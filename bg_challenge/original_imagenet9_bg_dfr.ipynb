{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate DFR on ImageNet-9 variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import einops\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_in9 = {}\n",
    "with open('in_to_in9.json', 'r') as f:\n",
    "    map_to_in9.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path):\n",
    "    arr = np.load(path)\n",
    "    x, y = arr[\"embeddings\"], arr[\"labels\"]\n",
    "    if np.max(y) > 9:\n",
    "        y = np.array([map_to_in9[str(y_)] for y_ in y])\n",
    "        mask = y != -1\n",
    "        x, y = x[mask], y[mask]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(\n",
    "    x_train, y_train, eval_datasets, \n",
    "    n_epochs=1000, weight_decay=0., lr=1.,\n",
    "    verbose=0\n",
    "    ):\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train).float().cuda()\n",
    "    y_train = torch.from_numpy(y_train).long().cuda()\n",
    "    \n",
    "    d = x_train.shape[1]\n",
    "    model = torch.nn.Linear(d, 9).cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), weight_decay=weight_decay, lr=lr)\n",
    "    schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_epochs)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_train)\n",
    "        loss = criterion(pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        schedule.step()\n",
    "        acc = (torch.argmax(pred, -1) == y_train).detach().float().mean()\n",
    "        if verbose > 1 and epoch % (n_epochs // 10) == 0:\n",
    "            print(epoch, acc)\n",
    "    \n",
    "    results = {}\n",
    "    for key, (x_test, y_test) in eval_datasets.items():\n",
    "        x_test = torch.from_numpy(x_test).float().cuda()\n",
    "        pred = torch.argmax(model(x_test), axis=-1).detach().cpu().numpy()\n",
    "        results[key] = (pred == y_test).mean()\n",
    "    \n",
    "    pred = torch.argmax(model(x_train), axis=-1)\n",
    "    results[\"train\"] = (pred == y_train).detach().cpu().float().mean().item()\n",
    "\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "    train_datasets, eval_datasets, \n",
    "    num_mixrand=-1, num_original=0, preprocess=True):\n",
    "    x_train, y_train = train_datasets[\"bgc_original\"]\n",
    "    idx = np.arange(len(x_train))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num_original]\n",
    "    x_train = x_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    x_train_mr, y_train_mr = train_datasets[\"bgc_mixedrand\"]\n",
    "    idx = np.arange(len(x_train_mr))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num_mixrand]\n",
    "    x_train_mr = x_train_mr[idx]\n",
    "    y_train_mr = y_train_mr[idx]\n",
    "\n",
    "    x_train = np.concatenate([x_train, x_train_mr])\n",
    "    y_train = np.concatenate([y_train, y_train_mr])\n",
    "\n",
    "    if preprocess:\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        eval_datasets_preprocessed = {\n",
    "            k: (scaler.transform(x), y)\n",
    "            for k, (x, y) in eval_datasets.items()\n",
    "        }\n",
    "    else:\n",
    "        eval_datasets_preprocessed = eval_datasets\n",
    "    return x_train, y_train, eval_datasets_preprocessed\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    train_datasets, eval_datasets,\n",
    "    num_mixrand=-1, num_original=0, preprocess=True,\n",
    "    n_epochs=1000, weight_decay=0., lr=1., verbose=0,\n",
    "    num_seeds=3\n",
    "):\n",
    "    print(lr)\n",
    "    print(weight_decay)\n",
    "    print(n_epochs)\n",
    "    results = {}\n",
    "    for seed in range(num_seeds):\n",
    "        x_train, y_train, eval_datasets_preprocessed = get_data(\n",
    "            train_datasets, eval_datasets,\n",
    "            num_mixrand, num_original, preprocess)\n",
    "        _, results_seed = train_logreg(\n",
    "            x_train, y_train, eval_datasets_preprocessed, \n",
    "            n_epochs, weight_decay, lr, verbose)\n",
    "        results[seed] = results_seed\n",
    "    \n",
    "    results_aggrgated = {\n",
    "        key: (np.mean([results[seed][key] for seed in results.keys()]),\n",
    "              np.std([results[seed][key] for seed in results.keys()]))\n",
    "        for key in results[0].keys()\n",
    "    }\n",
    "    return results, results_aggrgated\n",
    "\n",
    "\n",
    "def print_results(results_dict):\n",
    "    print(\"-------------------\")\n",
    "    for key, val in results_dict.items():\n",
    "        print(\"{}: {:.3f}±{:.3f}\".format(key, val[0], val[1]))\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change data paths here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_prev_layer = False\n",
    "\n",
    "eval_path_dict = {\n",
    "    \"imagenet_r\": f\"/home/jennyni/datasets/imagenet-r/imagenet-r_{use_prev_layer}_val_embeddings.npz\",\n",
    "    \"imagenet_a\": f\"/home/jennyni/datasets/imagenet-a/imagenet-a_{use_prev_layer}_val_embeddings.npz\",\n",
    "    \"bgc_original\": f\"/home/jennyni/datasets/bg_challenge/original/bg_challenge_{use_prev_layer}_val_embeddings.npz\",\n",
    "    \"bgc_fg\": f\"/home/jennyni/datasets/bg_challenge/only_fg/bg_challenge_{use_prev_layer}_val_embeddings.npz\",\n",
    "    \"bgc_mixedrand\": f\"/home/jennyni/datasets/bg_challenge/mixed_rand/bg_challenge_{use_prev_layer}_val_embeddings.npz\",\n",
    "    # \"bgc_paintings\": f\"/home/jennyni/datasets/bg_challenge/paintings_bg/bg_challenge_{use_prev_layer}_resnet50_val_embeddings.npz\"\n",
    "}\n",
    "\n",
    "eval_datasets = {k: load_embeddings(p) for k, p in eval_path_dict.items()}\n",
    "\n",
    "train_path_dict = {\n",
    "    # \"bgc_original\": f\"/home/jennyni/datasets/original/bg_challenge_{use_prev_layer}_train_standardSL_embeddings.npz\",\n",
    "    # \"bgc_mixedrand\": f\"/home/jennyni/datasets/mixed_rand/bg_challenge_{use_prev_layer}_train_standardSL_embeddings.npz\",\n",
    "    \"bgc_original\": f\"/home/jennyni/datasets/original/bg_challenge_{use_prev_layer}_train_embeddings.npz\",\n",
    "    \"bgc_mixedrand\": f\"/home/jennyni/datasets/mixed_rand/bg_challenge_{use_prev_layer}_train_embeddings.npz\",\n",
    "\n",
    "}\n",
    "train_datasets = {k: load_embeddings(p) for k, p in train_path_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1000, 5000, 10000, 20000, 45405]\n",
    "num_seeds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_results, results_original = run_experiment(train_datasets, eval_datasets,\n",
    "#                                                 num_mixrand=0, num_original=-1, num_seeds=num_seeds, n_epochs=2000,\n",
    "#                                                 weight_decay=100/45405)\n",
    "# print_results(results_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed-Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.1\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.477±0.016\n",
      "imagenet_a: 0.271±0.012\n",
      "bgc_original: 0.936±0.002\n",
      "bgc_fg: 0.893±0.006\n",
      "bgc_mixedrand: 0.863±0.003\n",
      "train: 1.000±0.000\n",
      "-------------------\n",
      "1.0\n",
      "0.02\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.526±0.012\n",
      "imagenet_a: 0.282±0.013\n",
      "bgc_original: 0.948±0.005\n",
      "bgc_fg: 0.917±0.005\n",
      "bgc_mixedrand: 0.895±0.004\n",
      "train: 0.977±0.001\n",
      "-------------------\n",
      "1.0\n",
      "0.01\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.535±0.006\n",
      "imagenet_a: 0.282±0.008\n",
      "bgc_original: 0.951±0.003\n",
      "bgc_fg: 0.922±0.005\n",
      "bgc_mixedrand: 0.909±0.001\n",
      "train: 0.955±0.001\n",
      "-------------------\n",
      "1.0\n",
      "0.005\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.536±0.006\n",
      "imagenet_a: 0.285±0.006\n",
      "bgc_original: 0.958±0.003\n",
      "bgc_fg: 0.932±0.003\n",
      "bgc_mixedrand: 0.919±0.001\n",
      "train: 0.936±0.001\n",
      "-------------------\n",
      "1.0\n",
      "0.0022024006166721727\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.554±0.000\n",
      "imagenet_a: 0.286±0.000\n",
      "bgc_original: 0.963±0.000\n",
      "bgc_fg: 0.939±0.000\n",
      "bgc_mixedrand: 0.926±0.000\n",
      "train: 0.919±0.000\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "mixrand_results_ns = []\n",
    "for n in ns:\n",
    "    num_mixrand = n\n",
    "    num_original = 0\n",
    "\n",
    "    n_data = num_mixrand + num_original\n",
    "    wd = 100 / n_data\n",
    "    n_epochs = 2000\n",
    "    seed_results, results_aggrgated = run_experiment(\n",
    "        train_datasets, eval_datasets,\n",
    "        num_mixrand, num_original, weight_decay=wd, n_epochs=n_epochs,\n",
    "        num_seeds=num_seeds)\n",
    "    print_results(results_aggrgated)\n",
    "    mixrand_results_ns.append(results_aggrgated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed-Rand + Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.05\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.510±0.015\n",
      "imagenet_a: 0.316±0.011\n",
      "bgc_original: 0.960±0.002\n",
      "bgc_fg: 0.913±0.007\n",
      "bgc_mixedrand: 0.876±0.005\n",
      "train: 0.999±0.001\n",
      "-------------------\n",
      "1.0\n",
      "0.01\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.525±0.019\n",
      "imagenet_a: 0.308±0.005\n",
      "bgc_original: 0.968±0.002\n",
      "bgc_fg: 0.926±0.006\n",
      "bgc_mixedrand: 0.901±0.004\n",
      "train: 0.982±0.002\n",
      "-------------------\n",
      "1.0\n",
      "0.005\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.527±0.006\n",
      "imagenet_a: 0.311±0.007\n",
      "bgc_original: 0.969±0.001\n",
      "bgc_fg: 0.932±0.004\n",
      "bgc_mixedrand: 0.911±0.001\n",
      "train: 0.969±0.001\n",
      "-------------------\n",
      "1.0\n",
      "0.0025\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.544±0.005\n",
      "imagenet_a: 0.313±0.007\n",
      "bgc_original: 0.972±0.001\n",
      "bgc_fg: 0.937±0.002\n",
      "bgc_mixedrand: 0.920±0.001\n",
      "train: 0.960±0.001\n",
      "-------------------\n",
      "1.0\n",
      "0.0011012003083360864\n",
      "2000\n",
      "-------------------\n",
      "imagenet_r: 0.556±0.000\n",
      "imagenet_a: 0.319±0.000\n",
      "bgc_original: 0.974±0.000\n",
      "bgc_fg: 0.943±0.000\n",
      "bgc_mixedrand: 0.925±0.000\n",
      "train: 0.950±0.000\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "combo_results_ns = []\n",
    "for n in ns:\n",
    "    num_mixrand = n\n",
    "    num_original = n\n",
    "\n",
    "    n_data = num_mixrand + num_original\n",
    "    wd = 100 / n_data\n",
    "    n_epochs = 2000\n",
    "    seed_results, results_aggrgated = run_experiment(\n",
    "        train_datasets, eval_datasets,\n",
    "        num_mixrand, num_original, weight_decay=wd, n_epochs=n_epochs,\n",
    "        num_seeds=num_seeds)\n",
    "    print_results(results_aggrgated)\n",
    "    combo_results_ns.append(results_aggrgated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(key, ax, ns, mixrand_results_ns, combo_results_ns, results_original):\n",
    "    mixrand_mu = np.array([results[key][0] for results in mixrand_results_ns])\n",
    "    mixrand_sigma = np.array([results[key][1] for results in mixrand_results_ns])\n",
    "\n",
    "    original_mu = np.array([results_original[key][0] for _ in ns])\n",
    "    original_sigma = np.array([results_original[key][1] for _ in ns])\n",
    "\n",
    "    combo_mu = np.array([results[key][0] for results in combo_results_ns])\n",
    "    combo_sigma = np.array([results[key][1] for results in combo_results_ns])\n",
    "    ax.plot(ns, mixrand_mu, \"-bo\", label=\"DFR MR\")\n",
    "    ax.fill_between(ns, mixrand_mu + mixrand_sigma, mixrand_mu - mixrand_sigma,\n",
    "                   color=\"b\", alpha=0.3)\n",
    "    ax.plot(ns, combo_mu, \"-ro\", label=\"DFR MR + Og\")\n",
    "    ax.fill_between(ns, combo_mu + combo_sigma, combo_mu - combo_sigma,\n",
    "                    color=\"r\", alpha=0.3)\n",
    "    ax.plot(ns, original_mu, \"--g\", label=\"DFR Og\")\n",
    "    ax.fill_between(ns, original_mu + original_sigma, original_mu - original_sigma,\n",
    "                    color=\"g\", alpha=0.3)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"# MixedRand Data\", fontsize=12)\n",
    "    ax.set_ylabel(f\"{key} Test Acc\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'imagenet_r': (0.5104353011329756, 0.014972363017504658), 'imagenet_a': (0.3155805846071333, 0.011301827107709715), 'bgc_original': (0.9603456790123456, 0.002155938760784507), 'bgc_fg': (0.9131851851851852, 0.007345585641070647), 'bgc_mixedrand': (0.8764938271604938, 0.0053127173561603215), 'train': (0.9991000056266784, 0.000663312823827469)}, {'imagenet_r': (0.5250911018352878, 0.018815568793173504), 'imagenet_a': (0.30834003754357736, 0.005142684269399035), 'bgc_original': (0.9679506172839506, 0.0019654072831736136), 'bgc_fg': (0.9257777777777777, 0.0057070697138542755), 'bgc_mixedrand': (0.9011358024691358, 0.0038079165725742165), 'train': (0.9822000026702881, 0.0015297118766521471)}, {'imagenet_r': (0.5271582852978203, 0.006235604151442249), 'imagenet_a': (0.3113971574148565, 0.006712571884006242), 'bgc_original': (0.9694320987654322, 0.0011086392257107966), 'bgc_fg': (0.9322962962962963, 0.004272104445211317), 'bgc_mixedrand': (0.9111604938271605, 0.001426126328710476), 'train': (0.9689599871635437, 0.0006044817984351858)}, {'imagenet_r': (0.544066785927251, 0.005304543588358345), 'imagenet_a': (0.31311343523732904, 0.006646249857724714), 'bgc_original': (0.9718518518518519, 0.0014227022509519164), 'bgc_fg': (0.9366913580246912, 0.0021784439506284422), 'bgc_mixedrand': (0.9203950617283951, 0.0013121313832677767), 'train': (0.9602349996566772, 0.0007863772801643043)}, {'imagenet_r': (0.5564963890545286, 0.0003174756125544365), 'imagenet_a': (0.318744971842317, 0.0003637613292102644), 'bgc_original': (0.9744197530864197, 0.0001209624564337682), 'bgc_fg': (0.9432592592592591, 0.00039506172839506577), 'bgc_mixedrand': (0.9253827160493827, 0.00036288736930125017), 'train': (0.9501068234443665, 5.842661931496945e-05)}]\n"
     ]
    }
   ],
   "source": [
    "print(combo_results_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_original' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m f, arr \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mbgc_mixedrand\u001b[39m\u001b[39m\"\u001b[39m, arr[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39marray(ns), mixrand_results_ns, combo_results_ns, results_original)\n\u001b[1;32m      4\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mbgc_fg\u001b[39m\u001b[39m\"\u001b[39m, arr[\u001b[39m1\u001b[39m], np\u001b[39m.\u001b[39marray(ns), mixrand_results_ns, combo_results_ns, results_original)\n\u001b[1;32m      5\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mbgc_original\u001b[39m\u001b[39m\"\u001b[39m, arr[\u001b[39m2\u001b[39m], np\u001b[39m.\u001b[39marray(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_original' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, arr = plt.subplots(1, 5, figsize=(16, 3))\n",
    "\n",
    "plot_results(\"bgc_mixedrand\", arr[0], np.array(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
    "plot_results(\"bgc_fg\", arr[1], np.array(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
    "plot_results(\"bgc_original\", arr[2], np.array(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
    "plot_results(\"imagenet_r\", arr[3], np.array(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
    "plot_results(\"imagenet_a\", arr[4], np.array(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
    "# plot_results(\"bgc_paintings\", arr[5], np.array(ns), mixrand_results_ns, combo_results_ns, results_original)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
